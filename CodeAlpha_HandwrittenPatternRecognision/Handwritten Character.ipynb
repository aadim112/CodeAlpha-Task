{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06355d92",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2edd54a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST(root='data', train=True, download=True, transform= ToTensor())\n",
    "test_data = datasets.MNIST(root='data', train=False, download=True, transform= ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c4833f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "image, label = train_data[0]\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5fbb19",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(train_data.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9fd8ef",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "image, label = train_data[1]\n",
    "print(f\"Image shape: {image.shape}\")\n",
    "plt.imshow(image.squeeze()) # image shape is [1, 28, 28] (colour channels, height, width)\n",
    "plt.title(label);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ef3683",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataloader = DataLoader(train_data,batch_size=BATCH_SIZE,shuffle=True)\n",
    "test_dataloader = DataLoader(test_data,batch_size=BATCH_SIZE,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5e5eb5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "# Create a model with non-linear and linear layers\n",
    "class FashionMNISTModelV1(nn.Module):\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Flatten(), # flatten inputs into single vector\n",
    "            nn.Linear(in_features=input_shape, out_features=hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_units, out_features=output_shape),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.layer_stack(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5da5c93",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model0 = FashionMNISTV0(input_shape=784,hidden_units=10,output_shape=10)\n",
    "model0.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb29746",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "# Download helper functions from Learn PyTorch repo (if not already downloaded)\n",
    "if Path(\"helper_functions.py\").is_file():\n",
    "  print(\"helper_functions.py already exists, skipping download\")\n",
    "else:\n",
    "  print(\"Downloading helper_functions.py\")\n",
    "  # Note: you need the \"raw\" GitHub URL for this to work\n",
    "  request = requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/helper_functions.py\")\n",
    "  with open(\"helper_functions.py\", \"wb\") as f:\n",
    "    f.write(request.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f97677",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from helper_functions import accuracy_fn\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=model0.parameters(),lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746a46fd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "def print_train_time(start: float, end: float, device: torch.device = None):\n",
    "  total_time = end - start\n",
    "  print(f\"Train time on {device}: {total_time:.3f} seconds\")\n",
    "  return total_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39147415",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Import tqdm for progress bar\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Set the seed and start the timer\n",
    "torch.manual_seed(42)\n",
    "train_time_start_on_cpu = timer()\n",
    "\n",
    "# Set the number of epochs (we'll keep this small for faster training times)\n",
    "epochs = 3\n",
    "\n",
    "# Create training and testing loop\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch}\\n-------\")\n",
    "    ### Training\n",
    "    train_loss = 0\n",
    "    # Add a loop to loop through training batches\n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        model0.train()\n",
    "        # 1. Forward pass\n",
    "        y_pred = model0(X)\n",
    "\n",
    "        # 2. Calculate loss (per batch)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss # accumulatively add up the loss per epoch\n",
    "\n",
    "        # 3. Optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. Loss backward\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. Optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print out how many samples have been seen\n",
    "        if batch % 400 == 0:\n",
    "            print(f\"Looked at {batch * len(X)}/{len(train_dataloader.dataset)} samples\")\n",
    "\n",
    "    # Divide total train loss by length of train dataloader (average loss per batch per epoch)\n",
    "    train_loss /= len(train_dataloader)\n",
    "\n",
    "    ### Testing\n",
    "    # Setup variables for accumulatively adding up loss and accuracy\n",
    "    test_loss, test_acc = 0, 0\n",
    "    model0.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X, y in test_dataloader:\n",
    "            # 1. Forward pass\n",
    "            test_pred = model0(X)\n",
    "\n",
    "            # 2. Calculate loss (accumulatively)\n",
    "            test_loss += loss_fn(test_pred, y) # accumulatively add up the loss per epoch\n",
    "\n",
    "            # 3. Calculate accuracy (preds need to be same as y_true)\n",
    "            test_acc += accuracy_fn(y_true=y, y_pred=test_pred.argmax(dim=1))\n",
    "\n",
    "        # Calculations on test metrics need to happen inside torch.inference_mode()\n",
    "        # Divide total test loss by length of test dataloader (per batch)\n",
    "        test_loss /= len(test_dataloader)\n",
    "\n",
    "        # Divide total accuracy by length of test dataloader (per batch)\n",
    "        test_acc /= len(test_dataloader)\n",
    "\n",
    "    ## Print out what's happening\n",
    "    print(f\"\\nTrain loss: {train_loss:.5f} | Test loss: {test_loss:.5f}, Test acc: {test_acc:.2f}%\\n\")\n",
    "\n",
    "# Calculate training time\n",
    "train_time_end_on_cpu = timer()\n",
    "total_train_time_model_0 = print_train_time(start=train_time_start_on_cpu,\n",
    "                                           end=train_time_end_on_cpu,\n",
    "                                           device=str(next(model0.parameters()).device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa067b47",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_custom_image(image_path):\n",
    "    \"\"\"\n",
    "    Converts any image into MNIST-compatible tensor:\n",
    "    - Handles RGB / Grayscale\n",
    "    - Resizes to 28x28\n",
    "    - Auto-inverts background if needed\n",
    "    - Normalizes properly\n",
    "    \"\"\"\n",
    "\n",
    "    # Load image\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    # Convert to grayscale\n",
    "    image = ImageOps.grayscale(image)\n",
    "\n",
    "    # Resize to MNIST dimensions\n",
    "    image = image.resize((28, 28))\n",
    "\n",
    "    # Convert to tensor\n",
    "    image_tensor = transforms.ToTensor()(image)\n",
    "\n",
    "    # Auto-invert if background is white\n",
    "    # MNIST digits are white on black background\n",
    "    if image_tensor.mean() > 0.5:\n",
    "        image_tensor = 1.0 - image_tensor\n",
    "\n",
    "    # Normalize (MNIST stats)\n",
    "    image_tensor = transforms.Normalize(\n",
    "        mean=(0.1307,),\n",
    "        std=(0.3081,)\n",
    "    )(image_tensor)\n",
    "\n",
    "    # Add batch dimension\n",
    "    image_tensor = image_tensor.unsqueeze(0)\n",
    "\n",
    "    return image_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0175df20",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps\n",
    "from torchvision import transforms\n",
    "\n",
    "# Redefine preprocess_custom_image within this cell to include the necessary imports\n",
    "# (This is done because the original function definition in KpiQfnpEpAdR was missing these imports,\n",
    "# and we are constrained to modify only this cell XGcc3_SK5yhZ.)\n",
    "def preprocess_custom_image(image_path):\n",
    "    \"\"\"\n",
    "    Converts any image into MNIST-compatible tensor:\n",
    "    - Handles RGB / Grayscale\n",
    "    - Resizes to 28x28\n",
    "    - Auto-inverts background if needed\n",
    "    - Normalizes properly\n",
    "    \"\"\"\n",
    "\n",
    "    # Load image\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    # Convert to grayscale\n",
    "    image = ImageOps.grayscale(image)\n",
    "\n",
    "    # Resize to MNIST dimensions\n",
    "    image = image.resize((28, 28))\n",
    "\n",
    "    # Convert to tensor\n",
    "    image_tensor = transforms.ToTensor()(image)\n",
    "\n",
    "    # Auto-invert if background is white\n",
    "    # MNIST digits are white on black background\n",
    "    if image_tensor.mean() > 0.5:\n",
    "        image_tensor = 1.0 - image_tensor\n",
    "\n",
    "    # Normalize (MNIST stats)\n",
    "    image_tensor = transforms.Normalize(\n",
    "        mean=(0.1307,),\n",
    "        std=(0.3081,)\n",
    "    )(image_tensor)\n",
    "\n",
    "    # Add batch dimension\n",
    "    image_tensor = image_tensor.unsqueeze(0)\n",
    "\n",
    "    return image_tensor\n",
    "\n",
    "image_path = \"/content/192869.png\"  # change this\n",
    "\n",
    "image_tensor = preprocess_custom_image(image_path)\n",
    "\n",
    "print(\"Processed image shape:\", image_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14684207",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(image_tensor.squeeze(), cmap=\"gray\")\n",
    "plt.title(\"Preprocessed Image\")\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348b236d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model0.eval()\n",
    "\n",
    "with torch.inference_mode():\n",
    "    logits = model0(image_tensor)\n",
    "    prediction = logits.argmax(dim=1).item()\n",
    "\n",
    "print(f\"Predicted digit: {prediction}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
